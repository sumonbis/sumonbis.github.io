<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Design | Sumon Biswas</title>
    <link>https://sumonbis.github.io/tag/design/</link>
      <atom:link href="https://sumonbis.github.io/tag/design/index.xml" rel="self" type="application/rss+xml" />
    <description>Design</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><copyright>© 2024 Sumon Biswas</copyright><lastBuildDate>Sat, 18 Dec 2021 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://sumonbis.github.io/media/logo_hu1013aaa6007864b42537cdd894cbbf97_22865_300x300_fit_lanczos_2.png</url>
      <title>Design</title>
      <link>https://sumonbis.github.io/tag/design/</link>
    </image>
    
    <item>
      <title>Design and Architecture of Data Science Pipelines</title>
      <link>https://sumonbis.github.io/project/design-architecture-ds/</link>
      <pubDate>Sat, 18 Dec 2021 00:00:00 +0000</pubDate>
      <guid>https://sumonbis.github.io/project/design-architecture-ds/</guid>
      <description>&lt;p&gt;Data science processes are becoming an integral component of many software systems today. In data-driven software, the processes are organized in several stages such as data acquisition, data preprocessing, modeling, training, evaluation, prediction, and so on, where the data flow from one stage to another. The stages with different subtasks, their connections, and feedback loops, create a new kind of software architecture called Data Science Pipeline. In order to design and build software systems with data science stages effectively, we must understand the structure of the data science pipelines. We demonstrated the importance of standardization and analysis framework for data science pipelines. We took the first step to understand the architecture and patterns of data science pipelines from theory and practice. &lt;/p&gt;
&lt;p&gt;We conducted a three-pronged study to draw observations from pipelines in the literature and popular press, smaller data science tasks, and large projects. They investigated the representation of the pipeline structure, its organization, and characteristics. What are the typical stages of a data science pipeline? How are they connected? Do the pipelines differ in the theoretical representations and that in the practice? Today we do not fully understand these architectural characteristics. The study resulted in three representative pipeline structures. The work also informs the terminology and design criteria for pipelines. For example, a number of stages from theory are absent in the pipelines in small data science programs without a clear separation of stages. On the other hand, the pipelines in large data science projects develop complex pipelines with feedback loops and sub-pipelines. The stage boundaries are stricter in large projects, which is necessary for scalability, maintenance, and testing of pipelines. The results will facilitate pipeline architects, practitioners, and software engineering teams to compare with existing and representative pipelines. For instance, a data scientist can identify whether the pipeline is missing any important stage or feedback loops in an earlier stage of development lifecycle, which will save much time and effort.&lt;/p&gt;
&lt;p&gt;We presented the results of the paper entitled &amp;ldquo;The Art and Practice of Data Science Pipelines: A Comprehensive Study of Data Science Pipelines In Theory, In-The-Small, and In-The-Large&amp;rdquo;, in the research technical track of the 44th International Conference on Software Engineering (ICSE 2022) held in Pittsburgh, PA, USA from May 21-29, 2022.&lt;/p&gt;
&lt;p&gt;The project has been supported in part by the National Science Foundation TRIPODS institute at ISU called D4 (Dependable Data-Driven Discovery). D4 has a broader goal of increasing dependability in data science pipelines by addressing various critical properties of pipelines such as fairness, complexity, uncertainty, and so on. The preprint of the paper is now available. Also, the artifact containing data and code are evaluated and published for future work in the area.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Safety Assurance of Predictive Systems</title>
      <link>https://sumonbis.github.io/project/precondition-inference/</link>
      <pubDate>Sat, 18 Dec 2021 00:00:00 +0000</pubDate>
      <guid>https://sumonbis.github.io/project/precondition-inference/</guid>
      <description>&lt;p&gt;Case Study: While long lines and frantically shuffling luggage into plastic bins isn’t a fun experience, airport security is a critical and necessary requirement for safe travel.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;No one understands the need for both thorough security screenings and short wait times more than U.S. Transportation Security Administration (TSA). They’re responsible for all U.S. airport security, screening more than two million passengers daily.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;As part of their Apex Screening at Speed Program, DHS has identified high false alarm rates as creating significant bottlenecks at the airport checkpoints. Whenever TSA’s sensors and algorithms predict a potential threat, TSA staff needs to engage in a secondary, manual screening process that slows everything down. And as the number of travelers increase every year and new threats develop, their prediction algorithms need to continually improve to meet the increased demand.&lt;/p&gt;
&lt;p&gt;The challenge is hosted in Kaggle by Department of Homeland Security which offered the largest prize pool in Kaggle’s history ($1.5 million) &lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;. The challenge is to reduce high false-alarm that create bottlenecks at airport systems. We aim to analyze the abstractions of the ML-enabled system to infer precondition that provide probable guarantees of safety of the system.&lt;/p&gt;
&lt;p&gt;Take the following solution of the challenge as an example. We analyze the source-code and look at the following abstraction of the system, where some low-level details are abstracted away &lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;














&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /project/precondition-inference/overview_hu0b05653f2fdd88134e828354e4e27e58_1722272_4e0c36c21c15a38b0fccb729f37a19f4.jpg 400w,
               /project/precondition-inference/overview_hu0b05653f2fdd88134e828354e4e27e58_1722272_42195b5aefb8dab3e3660d63bab0257c.jpg 760w,
               /project/precondition-inference/overview_hu0b05653f2fdd88134e828354e4e27e58_1722272_1200x1200_fit_q100_lanczos.jpg 1200w&#34;
               src=&#34;https://sumonbis.github.io/project/precondition-inference/overview_hu0b05653f2fdd88134e828354e4e27e58_1722272_4e0c36c21c15a38b0fccb729f37a19f4.jpg&#34;
               width=&#34;760&#34;
               height=&#34;198&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;p&gt;We propose the weakest precondition reasoning on the above abstraction to infer preconditions.
Specifically, we ask that, for a given post-condition of a component in the pipeline, what is the weakest precondition? Starting with the final stage in the pipeline, can we infer the weakest pre-condition and propagate that backward? Below is a one-step reasoning on the above pipeline to infer precondition of the correctness.&lt;/p&gt;














&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /project/precondition-inference/one-step_hu68bba872783e5c543d2c86ad9d215832_1262968_a6565348ef1f03816a0369fa983d99d6.jpg 400w,
               /project/precondition-inference/one-step_hu68bba872783e5c543d2c86ad9d215832_1262968_defaa56f0133a0f015321c582ed143ba.jpg 760w,
               /project/precondition-inference/one-step_hu68bba872783e5c543d2c86ad9d215832_1262968_1200x1200_fit_q100_lanczos.jpg 1200w&#34;
               src=&#34;https://sumonbis.github.io/project/precondition-inference/one-step_hu68bba872783e5c543d2c86ad9d215832_1262968_a6565348ef1f03816a0369fa983d99d6.jpg&#34;
               width=&#34;760&#34;
               height=&#34;320&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;p&gt;Then we aim to propagate the preconditions as much as possible, towards the inputs of the model. Thus, we can provide early signals and estimation of uncertainty. This will enable safety of the deep learning model by specifying false-negatives, which can bring severe safety risks.&lt;/p&gt;
&lt;section class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://www.kaggle.com/c/passenger-screening-algorithm-challenge/overview&#34;&gt;https://www.kaggle.com/c/passenger-screening-algorithm-challenge/overview&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:2&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/ShayanPersonal/Kaggle-Passenger-Screening-Challenge-Solution&#34;&gt;https://github.com/ShayanPersonal/Kaggle-Passenger-Screening-Challenge-Solution&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:2&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;
</description>
    </item>
    
    <item>
      <title>Verifying Neural Networks for Individual Fairness</title>
      <link>https://sumonbis.github.io/project/fairness-verification/</link>
      <pubDate>Sat, 18 Dec 2021 00:00:00 +0000</pubDate>
      <guid>https://sumonbis.github.io/project/fairness-verification/</guid>
      <description>&lt;p&gt;The availability of powerful computational resources and high volume of data has enabled the success of DNN in many applications. Although testing and verifying fairness of ML classifiers e.g., decision tree, support vector machine, received much attention recently, verification of DNN is hard because of the non-linear computational nodes in the network. We proposed Fairify that verifies individual fairness for DNNs in productions, which is recently published in ICSE 2023. The individual fairness property ensures that any two individuals with similar attributes except the protected attribute(s) should receive similar prediction.&lt;/p&gt;
&lt;p&gt;This property is extensively used in fairness testing literature. One reason for that is &amp;ndash; group fairness metrics can not capture unfairness when there is same discrimination for two different groups. But individual fairness measures worst-case situations. This property is challenging to verify because we have to check globally, compared to the adversarial robustness property where we are given a nominal input. I transferred the property as fairness pre- and post-condition of the DNN and then used SMT based technique to provide certification or counterexample. The verification has been made tractable in three steps:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Input partitioning&lt;/li&gt;
&lt;li&gt;Sound neural pruning&lt;/li&gt;
&lt;li&gt;Heuristic-based neural pruning.&lt;/li&gt;
&lt;/ol&gt;














&lt;figure  id=&#34;figure-neural-network-pruning-for-a-partition-of-the-input-domain&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Neural network pruning for a partition of the input domain.&#34; srcset=&#34;
               /project/fairness-verification/pruning_huf3efc34e3856e731db862923df29ff89_132196_485f96e6aee25cf33ba8bf8b5252c22d.jpg 400w,
               /project/fairness-verification/pruning_huf3efc34e3856e731db862923df29ff89_132196_0f4c917e3bd393acb761ab0f30197549.jpg 760w,
               /project/fairness-verification/pruning_huf3efc34e3856e731db862923df29ff89_132196_1200x1200_fit_q100_lanczos.jpg 1200w&#34;
               src=&#34;https://sumonbis.github.io/project/fairness-verification/pruning_huf3efc34e3856e731db862923df29ff89_132196_485f96e6aee25cf33ba8bf8b5252c22d.jpg&#34;
               width=&#34;760&#34;
               height=&#34;231&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Neural network pruning for a partition of the input domain.
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;The key idea behind the technique is that many neurons always remain inactive and hence do not impact decision-making, when we consider only a smaller part of the input domain. Therefore, Fairify divides the input space into smaller partitions and assigns a copy of DNN to each partition. Then Fairify employs interval arithmetic and layer-wise verification on each neuron to perform sound neural pruning. When the sound pruning is not sufficient, Fairify applies the heuristics of neural activation to prune further.&lt;/p&gt;
&lt;p&gt;The technique is scalable to real-world DNNs as well as to the relaxed version of fairness queries. Fairify can provide partial certification and locate fairness violations with counterexample, which would make fairness repair explainable and interactive.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
